{"experiment_id": "f916c86b0143", "timestamp": "2025-11-12T12:32:14.444210", "model_id": "global.anthropic.claude-sonnet-4-5-20250929-v1:0", "system_instructions": "You are a metadata curation assistant. Your task is to help improve and correct metadata \naccording to the specific instructions provided for each task. Be precise, accurate, and \nfollow the guidelines carefully.\n", "overall_metrics": {"total_samples": 40, "tasks_completed": 4, "tasks_failed": 0, "average_accuracy": 0.03031648112947441, "task_metrics": {"broadening_of_narrow_synonyms": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.02466200886613712, "min_score": 0.0, "max_score": 0.060240963855421686, "num_scored": 10}, "correction_of_typos": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.044600625289269454, "min_score": 0.0, "max_score": 0.11904761904761904, "num_scored": 10}, "narrowing_of_broad_synonyms": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.021182963208809517, "min_score": 0.0, "max_score": 0.06756756756756757, "num_scored": 10}, "translation_of_exact_synonyms": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.03082032715368154, "min_score": 0.0, "max_score": 0.08333333333333333, "num_scored": 10}}}}
{"experiment_id": "f916c86b0143", "timestamp": "2025-11-12T12:34:59.465131", "model_id": "global.anthropic.claude-sonnet-4-5-20250929-v1:0", "system_instructions": "You are a metadata curation assistant. Your task is to help improve and correct metadata \naccording to the specific instructions provided for each task. Be precise, accurate, and \nfollow the guidelines carefully.\n", "overall_metrics": {"total_samples": 40, "tasks_completed": 4, "tasks_failed": 0, "average_accuracy": 0.03035767126036494, "task_metrics": {"broadening_of_narrow_synonyms": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.02466200886613712, "min_score": 0.0, "max_score": 0.060240963855421686, "num_scored": 10}, "correction_of_typos": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.044600625289269454, "min_score": 0.0, "max_score": 0.11904761904761904, "num_scored": 10}, "narrowing_of_broad_synonyms": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.020371093108025644, "min_score": 0.0, "max_score": 0.06756756756756757, "num_scored": 10}, "translation_of_exact_synonyms": {"total_samples": 10, "successful_runs": 10, "failed_runs": 0, "success_rate": 1.0, "average_score": 0.031796957778027546, "min_score": 0.0, "max_score": 0.08333333333333333, "num_scored": 10}}}}
